---
´typora-root-url: ../img
---

##Kafka分布式发布订阅消息系统

Flume: 不同的数据源采集到落地到一个位置 source channel sink看做一个agent ,一个整体

Kafka: 不同集群和集群之间, broker producer consumer.生产者发布消息,缓存到broker_list, consumer订阅消息(消息的topic主题) 

都属于日志采集系统.

###Kafka背景

遇到问题:

分析一下用户实时行为, 以便设计出更好的广告位

对用户的搜索关键词进行统计,分析出当前的流行趋势

有些数据, 存储数据库太浪费,存储硬盘效率低(数据用完就丢弃了)

### Kafka介绍

数据不落地到磁盘,而落地到Kafka.

flume—>kafka—>storm

#### 特性

- 高吞吐:在商用机器上可以处理每秒数十万条信息
- 可以保存足够大的未处理的消息
  - Kafka可以把数据缓冲到Kafka集群(broker节点上,而且卡夫卡提供了数据备份)
- 支持压缩(gzip, snappy)
- 通过在O(1)代表时间复杂度的磁盘数据结构上提供消息持久化,对于即使数以TB的消息存储也能保持长时间的稳定性能

注:

why不制造一个超级计算机?

因为磁盘的寻址太慢

- 分布式系统,易与扩展

  producer broker consumer都会有多个,均为分布式, 无需停机即可扩展机器

  broker相当于flume里的agent,是核心,它的个数决定了卡夫卡的吞吐量,broker只用来缓存数据

- 消息被处理的状态是在consumer端维护,而不是由server端维护,当失败时能自动平衡

  server端存放的数据坏了,能自动恢复

- 支持online和offline的场景

### Kafka原理与架构

- kafka主要用于处理活跃的流式数据.
- 传统的日志分析系统(hive,mr)提供了一种离线处理日志信息的可扩展方案,但如果需要进行实时处理,通常会有较大延迟
- kafka的作用类似于缓存, 即活跃的数据和离线处理系统之间的缓存.
- ![](/Users/lijingwan/Documents/img/屏幕快照 2018-03-30 下午2.42.20.png)

![](/屏幕快照 2018-03-30 下午2.42.20.png)

Front End可以是Flume集群,Socket,hadoop集群都可以充当生产者,只要push数据,即是生产者.

虚线: 都需要在zk中注册临时节点

broker的负载均衡问题,由zk来协调

kafka对数据存放副本. 副本的角色需要zk来决定

消费者和zk: 当消费者订阅了某主题的消息,如果kafka出现了新消息,zk第一时间知道,并通知消费者去broke里拿消息

区分:(都可以完成数据采集)

​	flume : 更像一个管道,屏蔽源和目标之间的差异. (一台节点就可以工作),更像一个小作坊.

​	卡夫卡: 全局的视点,更像一个平台(是一个集群)

- 一个典型的卡夫卡集群包含若干producer,若干broker,若干consumer group,一个zookeeper集群. kafka通过zk管理集群配置,选举leader(broker中的leader,对外服务的),以及在consumer group时进行rebalance(消费者从另一个broker拿数据)

###Kafka的核心概念

- message

  message(消息)是通信的基本单位,每个producer可以向一个topic(主题)发布一些消息. 如果consumer订阅了这个主题,那么新发布的消息就会广播给这些consumer

- producer

  - 向broker发送消息
  - 可以通过任意一个broker发现其他broker的位置信息(借助zk: broker向zk注册临时节点)
  - 两种数据发送的方式
    - 同步发送(默认方式) 批发送,一批数据一起发送
    - 异步发送(修改producer.type配置)— 由专门的发送线程去发送.(callThread->sendThread) 可以压缩

- broker

  - producer和consumer之间的桥梁

    - 从producer端接收消息,并保存下来(push)
    - 将消息发送给订阅的consumer(pull)

  - 将消息可靠的缓存一段时间(用户自定义时间, TB级别的)

  - 轻量级实现

    - 处理TCP连接
    - 管理打开的文件句柄(分区,每个区对应一个文件夹,每个文件夹对应多个文件,—>句柄)

  - producer向文件中追加消息(顺序写)

    ​	注意:顺序写比随机写内存的效率还要高

  - consumer从文件中读取一定范围的消息(顺序读)

- topic

  - 类别: 物理上不同topic的消息分开存储, 逻辑上一个Topic的消息虽然保存于一个或多个broker上,但用户只需要指定消息的Topic即可生产或消费数据而不必关心数据存于何处)

    不属于任何topic不能缓存.

  - 对每个topic..kafka对它的日志(即消息)进行了分区

    ![](/Users/lijingwan/Documents/img/屏幕快照 2018-03-30 下午3.42.11.png)

    ![](/屏幕快照 2018-03-30 下午3.42.11.png)

  - Partition

    - 为了提高吞吐率,物理上把topic分成一个或者多个Partition(可以分别写入),每个Partition在物理上对应一个文件夹,该文件夹下存储这个partition的所有消息和索引文件
    - 每个分区都由一系列有序的, 不可变的消息组成,这些消息被连续的追加到分区的
    - 顺序写磁盘,效率非常高.(吞吐率高)

  - Replication

    - 一旦1个或者多个broker当机, 则当机期间其上所有的partition都无法提供服务.若无法恢复,则数据丢失.

      特别是集群规模上升到一定程度,当机的可能性大大提高—>replication机制重要

    - 为了更好的负载均衡.kafka尽量将所有的partition均匀分配到整个集群上. 一个典型的部署方式是一个topic的partition数量大于broker的数量! 同时,也需要将partition的副本尽量分散到不同的broker上. 

      ![](/Users/lijingwan/Documents/img/屏幕快照 2018-03-30 下午3.53.43.png)

      ![](/屏幕快照 2018-03-30 下午3.53.43.png)

      zookeeper确定leader,producer先向其写数据.

  - consumer

    - 发布消息的方式: 队列模式:(queuing):每个消息只能被一个consumer读到.

      ​		   发布-订阅模式:(publish-subscribe):广播到所有

      一般的消费模式是队列模式.

    - consumer可以加入一个consumer组,共同竞争一个topic, topic的消息将被分发到组中的==一个成员==.

      同一组的consumer可以在不同的程序中,也可以在不同机器上.

      如果所有的consumer都在一个组中,这就成为了传统的队列模式, 组间是订阅者模式.

      (注:只有broker会有负载均衡)

      更常见的,每个topic都有若干consumer组.每个组都是逻辑上的订阅者.(订阅者是组)

  - Zookeeper

    - 协调producer, broker 与 consumer
    - 状态追踪(是否当机)
    - 负载均衡(partition的列表,去做负载均衡)

###使用场景

- 在线与离线
- 跨数据中心的数据备份与集成(一个数据中心,即一个集群)
- 实时计算:相当于缓存

### 安装与部署

安装0.8版本kafka (最新版本:1.1.0)

partition 根据物理磁盘的大小,去自由分配(区分hadoop的128M)

卡夫卡在创建主题的时候,要在zookeeper上注册的.(主题的元信息要缓存到zookeeper上)

生产者和消费者: 可以在同一个节点上(是不同的程序),一个节点上可以开启多个消费者

master:9092 

####1.解压

tar -zxvf kafka…..

#### 2. 配置kafka

#####master节点

cd kafka….

vim config/server.properties

修改项:  

- broker.id=0 
- host.name=master
- num.partitions=3( 3个节点)

		一个topic对应3个partitions,partitions根据物理磁盘大小自动分配的

- zookeeper.connect=master:2181,slave1:2181,slave2:2181

#####将kafka复制到从节点slave1, slave2

##### 在从节点上修改server.properties

####3.启动zookeeper

####4. 启动kafka

3个节点上分别启动kafka

bin/kafka-server-start.sh -daemon config/server.properties

zkCli.sh -server master:2181

ls /  —>看到卡夫卡在zk上注册了好多节点

#### 5. 验证kafka

> 注意: kafka有shell命令也有java接口!

- 使用shell命令

  1. 创建一个test的主题(可以在任何一个节点上创建)

     创建主题时要指定zookeeper,因为主题相关的元信息要存放在zk上.

  bin/kafka-topics.sh  - -create  - -zookeeper master:2181  - -replication-factor 3 - -partitions 3  - -topic test

  指定一个节点的zk就可以! zk可以同步(这里指定分区,相当于把配置文件的分区覆盖掉了 )

  3个副本中,有一个leader,它主要是去做和客户端交互的.

  zk中: ls /brokers——>可以看到topics文件夹

  2. 在一个终端上启动一个生产者

     生产者可以是外部的一段应用程序,也可以是一个shell脚本

  kafka脚本: kafka-console-producer.sh

  bin/kafka-console-producer.sh   - -broker-list  master:9092  - -topic  test

  3. 键入下面的信息

     明天会更好

     Hello world !

  4. 在另一个终端上启动一个消费者

     bin/kafka-console-consumer.sh - -zookeeper slave1:2181 - - topic  test  - -from-beginning

  5. 如果发现屏幕上有同样的信息输出,证明Kafka已经搭建成功.

注: 生产者和消费者是不同的应用程序,故可以在同一个节点上. 

​	可以开多个终端启动多个消费者.(广播模式)

### 复习

看主题—>zk 中 ls /brokers

​			ls /brokers/topics

创建主题: bin/kafka-topics.sh —create —zookeeper  master:2181, slave1:2181,slave2:2181 —replication-factor 3 —partitions 3 —topic custormer-topic

分区个数>集群的个数,负载均衡做的更均匀

新建生产者: bin/kafka-console-producer.sh  —broker-list master:9092, slave1:9092, slave2:9092 —topic customer-topic

消费者:bin/kafka-console-consumer.sh —zookeeper master:2181,slave1:2181,slave2:2181 —topic customer-topic —from-beginning 可以开启多个消费者(同一个master上也可以)

卡夫卡是顺序写磁盘,也是一个集群. 底层是分区.

flume先将数据落地到hdfs, 然后storm从hdfs中读数据进行处理

可以不落地到hdfs,直接落地到kafka

### Java与kafka

1. eclipse —— 导入kafka相关的jar包: kafka—libs

   (用java开发,就是开发一个生产者,一个消费者)

2. 导入卡夫卡的源码包(卡夫卡是scala写的,很像java)

   Java做开发, 指的是 开发一个生产者,再开发一个消费者

3. 创建生产者和消费者

- 生产者      Simpleproducer.java

```java
package com.xdl.kafka;  
      
    import java.util.Properties;  
      
    import kafka.javaapi.producer.Producer;  
    import kafka.producer.KeyedMessage;  
    import kafka.producer.ProducerConfig;  
      
     
    public class SimpleProducer {  
        private static Producer<Integer,String> producer;  
        private final Properties props=new Properties();  
        public SimpleProducer(){  
            //定义连接的broker list  
            props.put("metadata.broker.list", "185.16.157.145:9092"); 
            //定义序列化类（Java对象传输前要序列化）  
            props.put("serializer.class", "kafka.serializer.StringEncoder");  
        //properties实际上继承自hashtable,主要用于存放配置信息
            producer = new Producer<Integer, String>(new ProducerConfig(props));  
        }  
        
        public static void main(String[] args) {  
            //做初始化工作(sp创建的时候会调用构造函数)
            SimpleProducer sp = new SimpleProducer();  
            //定义topic  
            String topic="student-topic";  
            //定义要发送给topic的消息  
            String messageStr = "send a message to broker BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB";  
            //构建消息对象  
            //Integer 代表分区 ,括号中的代表有参构造方法. 如果不指定,因为在配置文件中已经配置了分区数,所以kafka会默认根据负载情况,默认的发送到某分区.
            KeyedMessage<Integer, String> data = 
            		new KeyedMessage<Integer, String>(topic, messageStr); 
            //推送消息到broker  
            producer.send(data);  
            producer.close();  
        }  
    }  

```

//执行producer失败! 原因: 没有此主题

解决方案: cd kafka_2.10-0.8.2.2

​		bin/kafka-topics.sh —create —zookeeper master:2181  —replication-factor 3 --partitiosns 3 —topic student-topic 

​		zk命令行里: 查看此主题(看到已经存在此主题的分区是3)

生产消息时:加while循环,可以不停的生产消息.

- 消费者    Simpleproducer.java

```java
    package com.xdl.kafka;  
      
    import java.util.HashMap;  
    import java.util.List;  
    import java.util.Map;  
    import java.util.Properties;  
      
    import kafka.consumer.Consumer;  
    import kafka.consumer.ConsumerConfig;  
    import kafka.consumer.ConsumerIterator;  
    import kafka.consumer.KafkaStream;  
    import kafka.javaapi.consumer.ConsumerConnector;  
      
    public class SimpleHLConsumer {  
        private final ConsumerConnector consumer;  
        private final String topic;  
      
        public SimpleHLConsumer(String zookeeper, String groupId, String topic) {  
            Properties props = new Properties();  
            //定义连接zookeeper信息  
            props.put("zookeeper.connect", zookeeper);  
            //定义Consumer所有的groupID，关于groupID，后面会继续介绍  
            props.put("group.id", groupId);  
            //设置zookeeper session的连接时长
            props.put("zookeeper.session.timeout.ms", "500");  
            //zookeeper的同步时间
            props.put("zookeeper.sync.time.ms", "250");  
            //自动轮循的时间
            props.put("auto.commit.interval.ms", "1000");  
            consumer = Consumer.createJavaConsumerConnector(new ConsumerConfig(props));  
            this.topic = topic;  
        }  
      
        public void testConsumer() {  
            //代表主题的消息条数(即我们一次可以消费几条数据) topicCount可以添加多个topic
            Map<String, Integer> topicCount = new HashMap<String, Integer>();  
            //定义订阅topic数量  //对于topic主题,每次消费1条数据
            topicCount.put(topic, new Integer(1));  
            /*如果有多个topic
            	写法:String topic2 = "test";
            		topicCount.put(topic2, new Integer(1));
            */
            //返回的是所有topic的Map //List是主题下的消息,kafka的消息是以key和value对出现的,key和value都是一个byte[]数组
            //kafka的stream就代表kafka的消息
            //map里的String是主题,List是消息(根据个数,决定list的大小)
            Map<String, List<KafkaStream<byte[], byte[]>>> consumerStreams = consumer.createMessageStreams(topicCount);  
            //取出我们要需要的topic中的消息流  
            List<KafkaStream<byte[], byte[]>> streams = consumerStreams.get(topic);  
            for (final KafkaStream stream : streams) {  
                ConsumerIterator<byte[], byte[]> consumerIte = stream.iterator();  
                while (consumerIte.hasNext())  
                    System.out.println("Message from Single Topic :: " + new String(consumerIte.next().message()));  
            }  
            if (consumer != null)  
                consumer.shutdown();  
        }  
      
        public static void main(String[] args) {  
            String topic = "student-topic";  
            SimpleHLConsumer simpleHLConsumer = new SimpleHLConsumer("192.16.185.199:2181,192.16.185.200:2181,192.16.185.201:2181", "testgroup", topic);  
            simpleHLConsumer.testConsumer();  
        }  
      
    }  
```

//发送消息时是KeyedMassage    消费消息时是:KafkaStream

 cd  /tmp/kafka-logs 中存放kafka日志!   即落地位置

在config中的 server.properties中配置!

4. consumer分组的情况:

   写consumer2.java

   将组名改为 testgroup2

   分别运行2个.java,  都可以消费到消息(2个组,但分别只有一个成员)

5. 2个consumer在一个组内:

   上一步的组名改为和consumer一样的,只有一个消费者可以消费到

## 整合

### Kafka整合Flume

1. 准备jar包

- 将Kafka主目录lib下的如下jar拷贝至Flume的lib目录下

​    注意在Flume1.6.0的版本下面这些包就不用导入了，flume依赖包中已经有了。

kafka_2.10-0.8.2.1.jar、kafka-clients-0.8.2.1.jar、jopt-simple-3.2.jar、metrics-core-2.2.0.jar、scala-library-2.10.4.jar、zkclient-0.3.jar  ==在flume1.6.0以后(对应kafka0.8.1)就不用导了==

- 将jar拷贝至flume主目录下  插件包flumeng-kafka-plugin.jar
- 配置==flume.conf==(flume的conf目录下)
- 注意:
  - 新建/home/xdl/logs目录,否则会提示错误!

```conf
#agent section
producer.sources=s
producer.channels=c
producer.sinks=r

#sources section
producer.sources.s.channels=c
producer.sources.s.type=exec
producer.sources.s.command=tail -F /home/xdl/logs/test.log 

producer.sinks.r.type=org.apache.flume.plugins.KafkaSink
producer.sinks.r.metadata.broker.list=master:9092,slave1:9092,slave2:9092

producer.sinks.r.serializer.class=kafka.serializer.StringEncoder
producer.sinks.r.request.required.acks=-1
producer.sinks.r.max.message.size=1000000
producer.sinks.r.custom.encoding=UTF-8
producer.sinks.r.custom.topic.name=test-topic

producer.sinks.r.channel=c

producer.channels.c.type=memory
producer.channels.c.capacity=100000
producer.channels.c.transactionCapacity=1000
```

​	source type=exec  ------执行查看最新日志文件test.log

​	sink: 以前的类型hbase, hdfs ,logger

​         改为: KafkaSink( 来源于刚导入的插件 )

​         指定broker.list

​	序列化: flume采集到的数据缓存到kafka磁盘. 必须序列化

​		     写磁盘就要序列化.(之前写hdfs, 是用avo写, avo本身就已经是序列化框架了)

​	  当acer=-1 : kafka3个副本, 选择一个为leader(对外提供服务)另外两个follower,仅仅做备份. 当acer= -1, 意味着follower确认收到数据时才算一次发送完成.

​	当acer=1时, producer在leader确认后发送下一条message

最大发送msg字节数 max.message.size=100000

​	producer.sinks.r.producer.type=sync (prodecer向broker发送的类型 :有分 同步和异步 )

​	custom.encoding = UTF_8

​	指定topic的名字

​	channel类型 memory (还有file)

- 在zk中查看主题是否有,没有需要建立!zkCli.sh -server master:2181 

  ls /brokers 查看

- 启动Flume服务:写脚本

  - flume.bash : cd apache-flume-…..中

```java
bin/flume-ng agent -n producer -c conf -f ./conf/flume.conf -Dflume.root.logger=INFO,console>./flume.log 2>&1 1
```

注意: bash flume.bash后,一定要看是否多了一个application进程!! 如果没有,则flume没有启动!

- 向cd ~/logs/test.log 写数据: echo "hello" >> /home/xdl/logs/test.log  (这个目录需要提前建好,文件会自动生成!)

- 启动kafka的consumer.

  bin/kafka-console-consumer.sh --zookeeper
  master:2181 --topic test-topic --from-beginning

  可以看到控制台打印出的信息.

### Kafka整合Storm

kafka里发消息,一次发一条.  trident发多条

1. 导jar包,插件包

   …………………异常处理………………….

   hadoop-daemon.sh start namonode //单独启动namenode

   //元数据丢失,由于非法关机

   cd hadoopdata

   rm - rf ./*

   ssh slave1, slave2

   仍然删除hadoopdata 

   回到主节点: hdfs namenode -format 

   start-all.sh

   ……………………………………………………

   启动kafka

   bin/kafka-server-start.sh -daemon config/server.properties

   3个节点分别启动kafka

2. kafka生产者的创建

3. 创建消费kafka的topology

代码部分:

4. storm nimbus >/dev/null 2>&1 &

   storm ui > /dev/null 2>&1 &

   3个节点分别启动

   storm supervisor > /dev/null 2>&1 &

5. 提交:

   storm jar kafkastorm.jar  com.stone.test.KafkaSpoutTestTopology kafka-storm master 

   ​

6. 异常 not fount class

   将kafka的相关包, 导入storm,google的也要导入!

   cp ~/kafka_2.,…../lib    /home/xdl/apache-storm0.9.6/lib

   3个节点都要导包

**执行方式:**

1.  在eclipse中执行

2. 导成jar包执行(需要写入参数,并且重启storm(3个节点都重启!))

   导jar包时, lib也要导入!

------------小结-----------------

代码包com.stone.test

1. SendMessageProducer.java

   里面要配置zookeeper集群, broker list

   要在zookeeper中创建主题 house7

   zkCli.sh -server master:2181

   CountTopology.java

2. 将工程整体打包.

3. 先启动storm storm nimbus > /dev/null 2>&1 &

4. storm jar kafkastorm.jar com.stone.test.KafkaSpoutTestTopology master

出异常: Error kafka/api/OffsetRequest

cd kafka_2.10_0.8.2.2

cd libs

cp ./*  /home/xdl/apache-storm-0.9.6/lib/

进入slave1的卡夫卡的lib

cp ./*  /home/xdl/apache-storm-0.9.6/lib/

 将谷歌的jar包也分别拷贝到3个节点的storm的lib下

cd apache-storm-0.9.6 

cd logs

查看日志! 看报了什么错~

