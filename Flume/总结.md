## 安装与部署

conf配置:

1. 安装

2. example.conf (在conf目录下)

   ```conf
   # Name the components on this agent
   # agent1:代理的名字
   agent1.sources = source1
   agent1.channels = channel1
   agent1.sinks = sink1

   # Describe/configure the source 
   # spooldir 目录池方式
   agent1.sources.source1.type = spooldir 目录池
   agent1.sources.source1.spoolDir=/home/xdl/flume/aboutyunlog 此目录要自己建!
   #配置往channel1传输数据
   agent1.sources.source1.channels = channel1
   agent1.sources.source1.fileHeader=false

   # Describe the sink
   agent1.sinks.sink1.type = hdfs
   agent1.sinks.sink1.hdfs.path=hdfs://master:9000/flume/aboutyunlog 此目录是自动创建!
   agent1.sinks.sink1.hdfs.fileType=DataStream
   agent1.sinks.sink1.writeFormat=TEXT
   # hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；
   agent1.sinks.sink1.hdfs.rollInterval=4
   #配置从channel1接收数据
   agent1.sinks.sink1.channel = channel1

   # Use a channel which buffers events inmemory
   agent1.channels.channel1.type = file
   agent1.channels.channel1.checkpointDir=/home/xdl/flume/aboutyun_check
   agent1.channels.channel1.dataDirs=/home/xdl/flume/aboutyun_data
   ```

   spooling directory source

   ​       此源允许您通过将要提取的文件放入磁盘上的“spooling”目录中来提取数据。此源将监视新文件的指定目录，并在新文件显示时解析新文件中的事件。事件解析逻辑是可插入的。在给定文件被完全读入通道之后，它被重命名以指示完成（或可选地被删除）。
   与Exec源不同，该源是可靠的，并且不会错过数据，即使Flume被重新启动或被杀死。为了换取这种可靠性，只有不可变，唯一命名的文件必须放入spooling目录中。 Flume尝试检测这些问题条件，如果违反则会大声失败：
   如果在放入spooling目录后写入文件，Flume将在其日志文件中打印一个错误并停止处理。
   如果以后重新使用文件名，Flume会在其日志文件中打印一个错误并停止处理。

   ​

3. 编写shell脚本

   bin/flume-ng agent -n agent1 -c conf -f conf/example.conf -Dflume.root.logger=DEBUG,console >./flume.log 2>&1 &

   ​

   注意：

   a.   让日志收集任务以后后台进程运行，且将运行日志重定向到./flume.log保存。

   b.   -Dflume.root.logger=DEBUG,console是输出调试信息，也可以在配置文件中配置。步骤如下：

   \# cd /root/software/apache-flume-1.5.0-bin/conf/

   \# vim log4j.properties

   注释掉flume.root.logger=INFO,LOGFILE选择flume.root.logger=DEBUG,console把日志打印到控制台。

4. 验证

   jps —>查看是否有Application进程

   可以查看flume.log ( apache-flume-1.6.0-bin 中,自动创建)看有无出错

5.常见异常

​	Error: File Channel transaction capacity cannot be greater than the capacity of the channel

​	原因：这是因为我在配置文件example中设置了
	agent1.channels.channel1.capacity = 100

​	解决方法：只需把这行去掉即可。

​	也可以同时设定：

​	\# channel的event个数

​	agent1.channels.channel1.capacity=1000

​	\#事务event个数

​	agent1.channels.channel1.transactionCapacity=100

## avro的应用场景

Avro案例:

环境:
两台pc均安装flume(这里可以使用一台机器看效果，标注两台好理解一些)
假定ip分别为172.17.0.2、172.17.0.3
1.在172.17.0.2上添加agent a1配置文件flume-1.5.0-bin/conf/avro.conf

```conf
a1.sources = r1
a1.sinks = k1
a1.channels = c1
a1.sources.r1.bind = master
a1.sources.r1.port = 4141
a1.sources.r1.type = avro
a1.sinks.k1.type = logger
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
a1.channels.c1.type = memory                          

```

2.在172.17.0.2上启动agent a1(bin下操作)
      flume-ng agent -c . -f $FLUME_HOME/conf/avro.conf -Dflume.root.logger=INFO,console -n a1 
3.在172.17.0.3使用avro-client发送文件(log.00是自己随意构造的文件)
      flume-ng avro-client -c . -H 172.17.0.2 -p 4141 -F log.00
4.可以在172.17.0.2的控制台看到log.00的内容

### 案例2

- 配置文件 testAvro.conf

  ​

  ```
  #test avro sources
  a1.sources=r1
  a1.channels=c1
  a1.sinks=k1

  a1.sources.r1.type = avro
  a1.sources.r1.channels=c1
  a1.sources.r1.bind=192.168.1.102
  a1.sources.r1.port=55555

  #Use a channel which buffers events in memory
  a1.channels.c1.type = memory
  a1.channels.c1.capacity=1000
  a1.channels.c1.transactionCapacity = 100

  #sink配置
  a1.sinks.k1.type=logger
  a1.sinks.k1.channel=c1
  ```

- 启动flume服务

  ```
  $ bin/flume-ng agent -c conf -f conf/testAvro.conf  -n a1   -Dflume.root.logger=INFO,console
  ```

- 测试

  ```
  $ bin/flume-ng avro-client -c conf -H 192.168.1.102 -p 55555  -F /app/logs/test.log
  ```

