---
typora-root-url: ../img
---

##复习Storm

#### Storm的概念

实时流数据处理的分布式系统 Twitter

Storm对于实时数据的处理类似于Hadoop的批处理

离线: MR  Hive

实时的: HBase,  Storm

####storm的核心组件:

1. Nimbus: 负责资源的分配和任务的调度
2. zookeeper: 负责Nimbus和Supervisor之间的协调

			心跳信息

			Topology的状态信息
		
			Nimbus分配给Supervisor的任务信息

3. Supervisor: 负责本节点上任务的执行监视,负责开启Worker进程
4. Topology: storm框架的作业
5. Job: 是MapReduce框架的作业
6. Worker: 真正Topology的执行者,是Topology的一个子集
7. task:  spouttask  bolttask
8. executor: 物理线程
9. 消息tuple: 值的列表叫做元组

			元组相当于数据库中的一条记录,元组中可以包含一个或者多个值

####Api:

​	  Tuple的生命周期: Tuple—>Values

​	  Values tuple = new Values("word");

​	Spout: 数据源 主动发射,会获取外部的数据源,产生元组发射到Topology中

​		BaseBasicSpout  extends Component Implements ISpout

​		BaseRichSpout

​		OutputFieldsDeclarer(); //用来声明tuple元组值的列名字

  		ISpout{

​			open();//初始化,发射器和TopologyContext

​			nextTuple(); //轮循调度产生tuple元组的方法

​			close(); //Topology被kill的时候

​			activate();

​			deactivate();

​			ack();// 发射出去的tuple被成功处理之后回调的确认方法

​			fail(); //发射出去的tuple处理失败时进行回调的方法

​		}

​	Bolt: 消息的处理者 被动的角色,不会主动发射元组.

​			BaseBasicBolt

​			BaseRichBolt

​			IBolt{

​				prepare(); //相当于Spout中的open方法,负责资源的初始化

​				execute(); // 执行者, 负责处理spout或者上游发送过来的tuple,还可以产生新的元组继续发射给下游的Bolt

​				cleanup(); // kill的时候会执行

​			}

#### Topology

 拓扑:是由一组Spout和bolt组成

TopologyBuilder builder =  new TopologyBuilder();

builder.setSpout(id, new Spout(), parallint);

builder.setBolt("…..").shuffleGrouping(id);

StormSubmmit.submmitTopology(topologyName,conf,builder.create());

localCluster.submitTopology(name, config, builder.create());

#### 流的分组

Storm Streamting

​	tuple的序列叫做流, 类似于字节的序列

​	流的分组:

- shuffleGrouping 随机分组,  每个Bolt任务得到相等的tuple数量
- fieldsGroupting: 字段分组, 
- AllGrouping : 每个spout都会向所有的bolt发送元组
- NoGrouping: 
- GlobalGrouping:全局分组发送的所有实例的源产生一个单一的目标元组实例（具体的说，是发送到                ID最低的task进行处理） 
- directGroupint

#### 综合案例

   	 WordSpout 负责数据源

   	SplitBolt 负责切分

​	CountBolt 负责统计

​	SaveBolt 负责将统计结果保存保存数据库

​	

---

# Flume

![](/屏幕快照 2018-04-02 下午8.19.38.png)

Flume: 海量的日志采集系统

sqoop: 导入数据, 只能用于离线,底层是一个MapReduce,更多用于批量加载

flume:导入数据 , 实时, 离线都可以, 速度,量都非常大(海量日志分布式)

#### Flume在大数据生态系统中的位置

Flume 可用于离线数据的采集也可以用于实时数据的采集

sqoop 只能用于离线数据的加载

####概念

Clouderal开源

分布式, 可靠, 高可用的海量日志采集系统

数据源可定制, 可扩展(可定制: 可以是来自系统日志,文件,目录,tcp socket的数据,有接口,实现接口就可以了)

数据存储系统可定制, 可扩展(屏蔽了数据源和目标存储系统之间的异构性)		

中间件: 屏蔽了数据源和数据存储系统的异构性. (jdbc也可以看成中间件,连接任意数据库)

数据源是web系统,存储到hdfs上,通过flume来操作.如果没有flume,必须自己写实现.(需要非常了解web系统和hdfs系统数据的传输才可以,因为hdfs是分布式的,web系统可能不是分布式的)

#### 版本— OG和NG

OG  老版本 0.9.x 或 cdh3,由agent, collector, master等组件 

​		   不够稳定,会出现采集数据的丢失

NG  新版本   agent,Client组件 1.x以上

why推出NG版?

1. 精简代码
2. 架构简化

#### FaceBook的Scribe

容错性好

架构: Scribe agent, Scribe(汇聚节点), 存储系统

#### Apache的Chukwa

专门支持hadoop集群日志分析

架构: Adaptor 数据源

​	HDFS	存储系统

​	Collector和Agent

​	Demux和 achieving

#### Linkedln的Kafka

特点:适合异构集群(如hadoop->storm,也可以做外围采集,区分flume:flume外围采集到hdfs)

可以缓存大量的消息.(flume中缓存的量很小)

架构: producer

​	  Broker: 经纪人

​	 Consumer

![](/屏幕快照 2018-03-29 上午10.45.49.png)

卡夫卡: 采集来的数据要落地,如果要落地到jdfs, 会出现集群读写问题.卡夫卡适合不同集群之间的通信.

### Flume NG特点

1. 只有一种角色的节点: 代理节点(agent)
2. 没有Collector,  master节点. 最核心的变化
3. 去除了physical nodes, logical nodes的概念和相关内容
4. agent节点的组成也发生了变化,脱离了zookeeper

![](/屏幕快照 2018-04-02 下午8.40.16.png)

agent由3部分组成:Source, Channel, Sink. 不可分割.

channel用于数据的缓存.

![](/屏幕快照 2018-04-02 下午8.44.10.png)

上一张图片没有指定传输的类型.

在有汇聚节点的图中, 制定了传输的类型avro.

不用zk做协调,每个点都是做独立的采集.

#### Flume NG核心概念

1. Event :Flume中处理数据的单位

   channel中会缓存大量的event

2. Client: 客户端. 可以是外部的web系统    

3. Agent
   - Source
   - Channel
   - Sink 
   - 其他组件: Interceptor(拦截), Channel Selector, Sink Processor //属于上面3个中的组件(都属于上面3个内部的组件)

> Event

- Event是Flume数据传输的基本单元
- Flume以事件的形式将数据从源头传送到最终的目的
- Event 由可选的header和载有数据的一个byte array构成
  - 载有的数据对flume是不透明的
  - Header是容纳了key-value字符串对的无序集合,key在集合中是唯一的
  - Header可以在上下文路由中使用扩展

> Client

- Client是一个将原始log包装成events并且发送它们到一个或多个agent的实体
- 目的是从数据源系统中解耦Flume
- 在flume的拓扑结构中不是必须的(可以是日志,可以是sdk?)

> Agent

- 一个agent包含Source, Channel, Sink和其他组件
- 它利用这些组件将events从一个节点传输到另一个节点或者最终目的地
- agent是flume流的基础部分
- flume为这些组件提供了配置, 生命周期管理, 监控支持

Agent之Source: 

1.  Source负责接收event或通过特殊机制产生event,并且将events批量的放到一个或多个Channel
2. 包含event驱动和轮询两种类型
3. 不同类型的source: Syslog,  Netcat, 监控目录池, tcpsyslog
4. 自动生成时间的source: Exec
5. 用于Agent和Agent之间通信的IPC Source: Avro, Thrift
6. Source必须至少和一个channel关联

Agent之Channel与Sink

![](/屏幕快照 2018-04-02 下午9.12.56.png)

类型:可以是数据库channel, 可以是缓存channel, 可以是文件系统

1. Channel位于Source和Sink之间, 用于缓存进来的event
2. 当Sink成功的将event发送到下一个channel或最终目的,event从Channel移除
3. 不同的Channel提供的持久化水平也是不一样的
4. Memory Channel: volatile(不稳定的)
5. File Channel: 基于WAL(预写式日志Write-Ahead_Logging)实现
6. JDBC Channel: 基于嵌入Database实现
7. Channel支持事务, 提供较弱的顺序保证
8. 可以和任何数量的Source和Sink工作

因为Flume是海量日志采集, 采集的数据量非常大, 所以sink如果不能及时处理,需要写缓存或磁盘(类似mr的中间结果要写磁盘)

Agent之其他组件 生产中很少使用

- Interceptor 二次开发(拦截器)
- Channel Selector
- Sink Processor 二次开发

注:一个完整的项目包括:数据采集, 数据存储, 数据计算, 可视化

####安装

Flume的安装包和源码包要一起安装!

一个source可对接多个channel,但是一个sink只从1个具体的channel获取数据!

在JDK已经配置好的情况下:

1. 解压：# tar  -zxvf apache-flume-1.5.0-bin.tar.gz

   \# tar  -zxvf apache-flume-1.5.0-src.tar.gz

   将apache-flume-1.5.0-src文件夹中的内容全部复制到apache-flume

   -1.5.0-bin文件中

   \# cp -ri apache-flume-1.5.0-src/* apache-flume-1.5.0-bin

2. vim /root/.bash_profile

   JDK环境变量设置, Flume环境变量设置

    环境变量生效：# source /root/.bash_profile

3. 配置文件设置:

   -  flume-env.sh

   修改 flume-env.sh 配置文件,主要是JAVA_HOME变量设置

   1) 打开flume-evn.sh的存放路径 

   \# cd/home/xdl/apache-flume-1.6.0-bin/conf

   2) 设置JAVA_HOME

   3) bin/flume-ng version 查看是否安装成功

   - 建立配置文件example

   **实现Flume监听文件夹，数据写入文件夹内时将数据汇聚到HDFS**

   1)conf下: 建立一个example.conf文件

   2)编写配置文件

   ….(见综合案例)

   3)编写shell脚本

   4)bash flume.bash执行脚本. 启动flume

   5) jps查看进程是否成功: Application

   6)查看生成的flume.log日志文件,看程序有无出错

   7) 往Flume监控的目录/home/xdl/flume/aboutyunlog下创建文件a.txt,  ls 会看到文件变为: a.txt.COMPLETED

   8) 查看成功上传到hdfs中的文件

### avro

avro是hadoop自带的一个序列化框架

### 案例

3台节点: master 汇聚节点

​		slave1 slave2  采集节点

avro或者thrift 可以实现文档1的结果作为文档2的source.

// 两个文档分别是flume执行时所需的配置文件，文档一收集的日志放到4545端口（该端口为自定义端口），做为文档2的source，文档2收集的数据在存放在hdfs上面。



